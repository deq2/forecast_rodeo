{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression for 2011-2018 target dates\n",
    "\n",
    "Carry out regression experiment for a fixed set of predictors and all 2011-2018 target dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload packages that are modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Plotting magic\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import sys\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import netCDF4\n",
    "import time\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "# Ensure that working directory is forecast_rodeo\n",
    "if os.path.basename(os.getcwd()) == \"experiments\":\n",
    "    # Navigate to forecast_rodeo\n",
    "    os.chdir(os.path.join(\"..\",\"..\"))\n",
    "if os.path.basename(os.getcwd()) != \"forecast_rodeo\":\n",
    "    raise Exception(\"You must be in the forecast_rodeo folder\")\n",
    "\n",
    "# Adds 'experiments' folder to path to load experiments_util\n",
    "sys.path.insert(0, 'src/experiments')\n",
    "# Load general utility functions\n",
    "from experiments_util import *\n",
    "# Load functionality for fitting and predicting\n",
    "from fit_and_predict import *\n",
    "# Load functionality for evaluation\n",
    "from skill import *\n",
    "# Load stepwise utility functions\n",
    "from stepwise_util import *\n",
    "\n",
    "# Experiment name\n",
    "experiment = \"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Choose target\n",
    "#\n",
    "gt_id = \"contest_tmp2m\" # \"contest_precip\" or \"contest_tmp2m\"\n",
    "target_horizon = \"34w\" # \"34w\" or \"56w\"\n",
    "\n",
    "#\n",
    "# Set variables based on target choice\n",
    "#\n",
    "\n",
    "# Identify measurement variable name\n",
    "measurement_variable = get_measurement_variable(gt_id) # 'tmp2m' or 'precip'\n",
    "\n",
    "# column names for gt_col, clim_col and anom_col \n",
    "gt_col = measurement_variable\n",
    "clim_col = measurement_variable+\"_clim\"\n",
    "anom_col = get_measurement_variable(gt_id)+\"_anom\" # 'tmp2m_anom' or 'precip_anom'\n",
    "\n",
    "# anom_inv_std_col: column name of inverse standard deviation of anomalies for each start_date\n",
    "anom_inv_std_col = anom_col+\"_inv_std\"\n",
    "\n",
    "# Name of knn columns\n",
    "knn_cols = [\"knn\"+str(ii) for ii in xrange(1,21)]\n",
    "\n",
    "#\n",
    "# Create list of official contest submission dates in YYYYMMDD format\n",
    "#\n",
    "submission_dates = [datetime(y,4,18)+timedelta(14*i) for y in range(2011,2018) for i in range(26)]\n",
    "submission_dates = ['{}{:02d}{:02d}'.format(date.year, date.month, date.day) for date in submission_dates]\n",
    "submission_dates = [datetime.strptime(str(d), \"%Y%m%d\") for d in submission_dates]\n",
    "submission_dates = pd.Series(submission_dates)\n",
    "\n",
    "#\n",
    "# Create list of target dates corresponding to submission dates in YYYYMMDD format\n",
    "#\n",
    "target_dates = pd.Series([get_target_date('{}{:02d}{:02d}'.format(date.year, date.month, date.day), target_horizon) for date in submission_dates])\n",
    "\n",
    "# Find all unique target day-month combinations\n",
    "target_day_months = pd.DataFrame({'month' : target_dates.dt.month, \n",
    "                                  'day': target_dates.dt.day}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['knn1', 'knn2', 'knn3', 'knn4', 'knn5', 'knn6', 'knn7', 'knn8', 'knn9', 'knn10', 'knn11', 'knn12', 'knn13', 'knn14', 'knn15', 'knn16', 'knn17', 'knn18', 'knn19', 'knn20', 'ones', 'tmp2m_shift29_anom', 'tmp2m_shift58_anom', 'tmp2m_shift365_anom']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Choose regression parameters\n",
    "#\n",
    "# Record standard settings of these parameters\n",
    "setting = \"knn_regression\"\n",
    "if setting == \"knn_regression\":\n",
    "    base_col = clim_col\n",
    "    # Number of KNN neighbors to use in regression\n",
    "    num_nbrs = 1 if gt_id.endswith('precip') else 20\n",
    "    x_cols = ['knn'+str(nbr) for nbr in xrange(1,num_nbrs+1)] + ['ones']\n",
    "    # Construct fixed lag anomaly variable names\n",
    "    lags = (['43', '86'] if target_horizon == '56w' else ['29', '58']) + ['365']\n",
    "    x_cols = x_cols + [measurement_variable+'_shift'+lag+'_anom' for lag in lags] \n",
    "    # Determine margin for local regression\n",
    "    margin_in_days = 56 if gt_id.endswith('precip') else None\n",
    "    # columns to group by when fitting regressions (a separate regression\n",
    "    # is fit for each group); use ['ones'] to fit a single regression to all points\n",
    "    group_by_cols = ['lat', 'lon']\n",
    "    # anom_scale_col: multiply anom_col by this amount prior to prediction\n",
    "    # (e.g., 'ones' or anom_inv_std_col)\n",
    "    anom_scale_col = anom_inv_std_col\n",
    "    # pred_anom_scale_col: multiply predicted anomalies by this amount\n",
    "    # (e.g., 'ones' or anom_inv_std_col)\n",
    "    pred_anom_scale_col = anom_scale_col\n",
    "elif setting == \"stepwise_no_model_selection\":\n",
    "    base_col = clim_col\n",
    "    x_cols = default_stepwise_candidate_predictors(gt_id, target_horizon, hindcast=False) + ['knn1']\n",
    "    margin_in_days = 56\n",
    "    group_by_cols = ['lat', 'lon']\n",
    "    anom_scale_col = anom_inv_std_col\n",
    "    pred_anom_scale_col = anom_scale_col\n",
    "\n",
    "print x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading date and lat lon date data\n",
      "Elapsed time: 7.014532 seconds.\n",
      "\n",
      "Restricting data to years >= 1979\n",
      "Elapsed time: 7.854232 seconds.\n",
      "\n",
      "Dropping rows with missing values for any relevant columns\n",
      "Elapsed time: 15.536588 seconds.\n",
      "\n",
      "Adding supplementary columns\n",
      "Elapsed time: 14.896080 seconds.\n",
      "\n",
      "Loading KNN data\n",
      "Elapsed time: 29.981443 seconds.\n",
      "\n",
      "Merge datasets\n",
      "   tmp2m_shift29_anom  tmp2m_shift365_anom    target  tmp2m_anom    lon  \\\n",
      "0           -1.017055            -6.193481  1.045174    1.045174  261.0   \n",
      "1           -1.011894            -6.533477  1.645593    1.645593  261.0   \n",
      "2           -1.320754            -6.079782  2.102227    2.102227  261.0   \n",
      "3           -1.537798            -4.923485  2.490746    2.490746  261.0   \n",
      "4           -1.715973            -4.072896  3.116631    3.116631  261.0   \n",
      "\n",
      "   tmp2m_clim  tmp2m_shift58_anom  ones   lat  sample_weight  ...  knn9  knn8  \\\n",
      "0   13.877076           -1.931445   1.0  27.0       0.193277  ...   NaN   NaN   \n",
      "1   13.817056           -1.785129   1.0  27.0       0.176419  ...   NaN   NaN   \n",
      "2   13.872171           -1.627251   1.0  27.0       0.164083  ...   NaN   NaN   \n",
      "3   13.829688           -1.332542   1.0  27.0       0.154847  ...   NaN   NaN   \n",
      "4   13.792283           -0.650069   1.0  27.0       0.141158  ...   NaN   NaN   \n",
      "\n",
      "   knn4  knn7  knn6  knn1  knn3  knn2  knn20  year  \n",
      "0   NaN   NaN   NaN   NaN   NaN   NaN    NaN  1980  \n",
      "1   NaN   NaN   NaN   NaN   NaN   NaN    NaN  1980  \n",
      "2   NaN   NaN   NaN   NaN   NaN   NaN    NaN  1980  \n",
      "3   NaN   NaN   NaN   NaN   NaN   NaN    NaN  1980  \n",
      "4   NaN   NaN   NaN   NaN   NaN   NaN    NaN  1980  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "Elapsed time: 87.484954 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Default regression parameter values\n",
    "#\n",
    "# choose first year to use in training set\n",
    "first_train_year = 1948 if gt_id == 'contest_precip' else 1979\n",
    "# specify regression model\n",
    "fit_intercept = False\n",
    "model = linear_model.LinearRegression(fit_intercept=fit_intercept)\n",
    "\n",
    "#\n",
    "# Prepare target and feature data\n",
    "#\n",
    "relevant_cols = set(x_cols+[base_col,clim_col,anom_col,'sample_weight','target',\n",
    "                    'start_date','lat','lon','year','ones']+group_by_cols)\n",
    "# Create dataset with relevant columns only; otherwise the dataframe is too big\n",
    "tic()\n",
    "print \"Loading date and lat lon date data\"\n",
    "data_dir = os.path.join(\"results\", experiment, \"shared\", gt_id + \"_\" + target_horizon)\n",
    "date_data = pd.read_hdf(os.path.join(data_dir, \"date_data-\" + gt_id + \"_\" + target_horizon + \".h5\"))\n",
    "date_data['year'] = date_data.start_date.dt.year\n",
    "lat_lon_date_data = pd.read_hdf(\n",
    "    os.path.join(data_dir, \"lat_lon_date_data-\" + gt_id + \"_\" + target_horizon + \".h5\"))\n",
    "toc()\n",
    "# Restrict data to years >= first_train_year\n",
    "tic()\n",
    "print \"Restricting data to years >= {}\".format(first_train_year)\n",
    "lat_lon_date_data = lat_lon_date_data.loc[lat_lon_date_data.start_date.dt.year >= first_train_year]\n",
    "date_data = date_data.loc[date_data.year >= first_train_year]\n",
    "toc()\n",
    "# Drop rows with missing values for any relevant column \n",
    "tic()\n",
    "print \"Dropping rows with missing values for any relevant columns\"\n",
    "relevant_lat_lon_date_cols = list(set(lat_lon_date_data.columns.tolist()) & relevant_cols)\n",
    "lat_lon_date_data.dropna(subset = relevant_lat_lon_date_cols, inplace = True)\n",
    "relevant_date_cols = list(set(date_data.columns.tolist()) & relevant_cols)\n",
    "date_data.dropna(subset = relevant_date_cols, inplace = True)\n",
    "toc()\n",
    "# Add supplementary columns\n",
    "tic()\n",
    "print \"Adding supplementary columns\"\n",
    "lat_lon_date_data['anom_inv_sqrt_2nd_mom'] = 1.0/np.sqrt(\n",
    "    lat_lon_date_data.groupby('start_date')[anom_col].transform('mean')**2\n",
    "    + lat_lon_date_data.groupby('start_date')[anom_col].transform('var',ddof=0))\n",
    "lat_lon_date_data['ones'] = 1.0\n",
    "lat_lon_date_data['zeros'] = 0.0\n",
    "# To minimize the mean-squared error between predictions of the form\n",
    "# (f(x_cols) + base_col - clim_col) * pred_anom_scale_col\n",
    "# and a target of the form anom_col * anom_scale_col, we will\n",
    "# estimate f using weighted least squares with datapoint weights\n",
    "# pred_anom_scale_col^2 and effective target variable \n",
    "# anom_col * anom_scale_col / pred_anom_scale_col + clim_col - base_col\n",
    "lat_lon_date_data['sample_weight'] = lat_lon_date_data[pred_anom_scale_col]**2\n",
    "lat_lon_date_data['target'] = (lat_lon_date_data[clim_col] - lat_lon_date_data[base_col] + \n",
    "                               lat_lon_date_data[anom_col] * lat_lon_date_data[anom_scale_col] / \n",
    "                              (lat_lon_date_data[pred_anom_scale_col]+(lat_lon_date_data[pred_anom_scale_col]==0)))\n",
    "toc()\n",
    "\n",
    "# Load KNN data\n",
    "tic()\n",
    "print \"Loading KNN data\"\n",
    "past_days = 60\n",
    "days_early = 337 if target_horizon == \"34w\" else 323\n",
    "max_nbrs = 20\n",
    "knn_dir = os.path.join(\"data\", \"dataframes\")\n",
    "knn_data = pd.read_hdf(\n",
    "    os.path.join(knn_dir, \n",
    "                 \"knn-{}-{}-days{}-early{}-maxnbrs{}.h5\".format(\n",
    "                     gt_id, target_horizon, past_days, days_early, max_nbrs)))\n",
    "relevant_knn_cols = list(set(knn_cols) & relevant_cols)\n",
    "# Divide knn anomalies by std dev across grid cells\n",
    "knn_data[relevant_knn_cols] /= knn_data.groupby([\"start_date\"])[relevant_knn_cols].transform('std')\n",
    "toc()\n",
    "\n",
    "# Restrict data to relevant columns\n",
    "tic()\n",
    "print \"Merge datasets\"\n",
    "relevant_lat_lon_date_cols = list(set(lat_lon_date_data.columns.tolist()) & relevant_cols)\n",
    "data = lat_lon_date_data.loc[:, relevant_lat_lon_date_cols]\n",
    "relevant_knn_cols = list(set(knn_data.columns.tolist()) & relevant_cols)\n",
    "data = pd.merge(data, knn_data[relevant_knn_cols],\n",
    "                on=[\"start_date\",\"lat\",\"lon\"], how=\"left\")\n",
    "data = pd.merge(data, date_data[relevant_date_cols],\n",
    "                on=\"start_date\", how=\"left\")\n",
    "print data.head()\n",
    "del lat_lon_date_data\n",
    "del knn_data\n",
    "del date_data\n",
    "toc()\n",
    "\n",
    "# Print warning if not all x columns were included\n",
    "s = [x for x in x_cols if x not in data.columns.tolist()]\n",
    "if s:\n",
    "    print \"These x columns were not found:\"\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_month=Pandas(Index=0, day=2, month=5), target=2011-05-02 00:00:00\n",
      "Elapsed time: 110.634363 seconds.\n",
      "\n",
      "running mean skill = 0.226607041983\n",
      "Elapsed time: 0.046922 seconds.\n",
      "\n",
      "day_month=Pandas(Index=1, day=16, month=5), target=2011-05-16 00:00:00\n",
      "Elapsed time: 108.636911 seconds.\n",
      "\n",
      "running mean skill = 0.141737205833\n",
      "Elapsed time: 0.067178 seconds.\n",
      "\n",
      "day_month=Pandas(Index=2, day=30, month=5), target=2011-05-30 00:00:00\n",
      "Elapsed time: 108.508837 seconds.\n",
      "\n",
      "running mean skill = 0.288329436148\n",
      "Elapsed time: 0.097602 seconds.\n",
      "\n",
      "day_month=Pandas(Index=3, day=13, month=6), target=2011-06-13 00:00:00\n",
      "Elapsed time: 109.159429 seconds.\n",
      "\n",
      "running mean skill = 0.306017968223\n",
      "Elapsed time: 0.114264 seconds.\n",
      "\n",
      "day_month=Pandas(Index=4, day=27, month=6), target=2011-06-27 00:00:00\n",
      "Elapsed time: 112.608668 seconds.\n",
      "\n",
      "running mean skill = 0.380045582218\n",
      "Elapsed time: 0.160544 seconds.\n",
      "\n",
      "day_month=Pandas(Index=5, day=11, month=7), target=2011-07-11 00:00:00\n",
      "Elapsed time: 105.847093 seconds.\n",
      "\n",
      "running mean skill = 0.386852535298\n",
      "Elapsed time: 0.174992 seconds.\n",
      "\n",
      "day_month=Pandas(Index=6, day=25, month=7), target=2011-07-25 00:00:00\n",
      "Elapsed time: 101.006089 seconds.\n",
      "\n",
      "running mean skill = 0.399681711422\n",
      "Elapsed time: 0.235089 seconds.\n",
      "\n",
      "day_month=Pandas(Index=7, day=8, month=8), target=2011-08-08 00:00:00\n",
      "Elapsed time: 96.102110 seconds.\n",
      "\n",
      "running mean skill = 0.391930603923\n",
      "Elapsed time: 0.220763 seconds.\n",
      "\n",
      "day_month=Pandas(Index=8, day=22, month=8), target=2011-08-22 00:00:00\n",
      "Elapsed time: 87.595390 seconds.\n",
      "\n",
      "running mean skill = 0.398712660387\n",
      "Elapsed time: 0.235764 seconds.\n",
      "\n",
      "day_month=Pandas(Index=9, day=5, month=9), target=2011-09-05 00:00:00\n",
      "Elapsed time: 78.200706 seconds.\n",
      "\n",
      "running mean skill = 0.398807398904\n",
      "Elapsed time: 0.250109 seconds.\n",
      "\n",
      "day_month=Pandas(Index=10, day=19, month=9), target=2011-09-19 00:00:00\n",
      "Elapsed time: 87.907565 seconds.\n",
      "\n",
      "running mean skill = 0.392400257873\n",
      "Elapsed time: 0.179277 seconds.\n",
      "\n",
      "day_month=Pandas(Index=11, day=3, month=10), target=2011-10-03 00:00:00\n",
      "Elapsed time: 87.587290 seconds.\n",
      "\n",
      "running mean skill = 0.372606054712\n",
      "Elapsed time: 0.218903 seconds.\n",
      "\n",
      "day_month=Pandas(Index=12, day=17, month=10), target=2011-10-17 00:00:00\n",
      "Elapsed time: 95.508196 seconds.\n",
      "\n",
      "running mean skill = 0.370032064805\n",
      "Elapsed time: 0.377820 seconds.\n",
      "\n",
      "day_month=Pandas(Index=13, day=31, month=10), target=2011-10-31 00:00:00\n",
      "Elapsed time: 108.130799 seconds.\n",
      "\n",
      "running mean skill = 0.354800658256\n",
      "Elapsed time: 0.386524 seconds.\n",
      "\n",
      "day_month=Pandas(Index=14, day=14, month=11), target=2011-11-14 00:00:00\n",
      "Elapsed time: 108.272268 seconds.\n",
      "\n",
      "running mean skill = 0.347883631303\n",
      "Elapsed time: 0.390552 seconds.\n",
      "\n",
      "day_month=Pandas(Index=15, day=28, month=11), target=2011-11-28 00:00:00\n",
      "Elapsed time: 109.711460 seconds.\n",
      "\n",
      "running mean skill = 0.342362593917\n",
      "Elapsed time: 0.395111 seconds.\n",
      "\n",
      "day_month=Pandas(Index=16, day=12, month=12), target=2011-12-12 00:00:00\n",
      "Elapsed time: 107.022927 seconds.\n",
      "\n",
      "running mean skill = 0.337033894677\n",
      "Elapsed time: 0.414993 seconds.\n",
      "\n",
      "day_month=Pandas(Index=17, day=26, month=12), target=2011-12-26 00:00:00\n",
      "Elapsed time: 107.479051 seconds.\n",
      "\n",
      "running mean skill = 0.300967755447\n",
      "Elapsed time: 0.401546 seconds.\n",
      "\n",
      "day_month=Pandas(Index=18, day=9, month=1), target=2011-01-09 00:00:00\n",
      "Elapsed time: 107.400417 seconds.\n",
      "\n",
      "running mean skill = 0.294632804252\n",
      "Elapsed time: 0.425235 seconds.\n",
      "\n",
      "day_month=Pandas(Index=19, day=23, month=1), target=2011-01-23 00:00:00\n",
      "Elapsed time: 106.091449 seconds.\n",
      "\n",
      "running mean skill = 0.302387305829\n",
      "Elapsed time: 0.395194 seconds.\n",
      "\n",
      "day_month=Pandas(Index=20, day=6, month=2), target=2011-02-06 00:00:00\n",
      "Elapsed time: 105.805096 seconds.\n",
      "\n",
      "running mean skill = 0.305366565239\n",
      "Elapsed time: 0.435738 seconds.\n",
      "\n",
      "day_month=Pandas(Index=21, day=20, month=2), target=2011-02-20 00:00:00\n",
      "Elapsed time: 100.684769 seconds.\n",
      "\n",
      "running mean skill = 0.293455442674\n",
      "Elapsed time: 0.491673 seconds.\n",
      "\n",
      "day_month=Pandas(Index=22, day=5, month=3), target=2011-03-05 00:00:00\n",
      "Elapsed time: 82.756367 seconds.\n",
      "\n",
      "running mean skill = 0.298187050613\n",
      "Elapsed time: 0.303858 seconds.\n",
      "\n",
      "day_month=Pandas(Index=23, day=19, month=3), target=2011-03-19 00:00:00\n",
      "Elapsed time: 94.902066 seconds.\n",
      "\n",
      "running mean skill = 0.302369061168\n",
      "Elapsed time: 0.489266 seconds.\n",
      "\n",
      "day_month=Pandas(Index=24, day=2, month=4), target=2011-04-02 00:00:00\n",
      "Elapsed time: 85.678851 seconds.\n",
      "\n",
      "running mean skill = 0.307246508962\n",
      "Elapsed time: 0.516321 seconds.\n",
      "\n",
      "day_month=Pandas(Index=25, day=16, month=4), target=2011-04-16 00:00:00\n",
      "Elapsed time: 90.320085 seconds.\n",
      "\n",
      "running mean skill = 0.30863685487\n",
      "Elapsed time: 0.542299 seconds.\n",
      "\n",
      "day_month=Pandas(Index=48, day=6, month=3), target=2011-03-06 00:00:00\n",
      "Elapsed time: 107.762773 seconds.\n",
      "\n",
      "running mean skill = 0.310659409653\n",
      "Elapsed time: 0.453534 seconds.\n",
      "\n",
      "day_month=Pandas(Index=49, day=20, month=3), target=2011-03-20 00:00:00\n",
      "Elapsed time: 108.243819 seconds.\n",
      "\n",
      "running mean skill = 0.313895190545\n",
      "Elapsed time: 0.553699 seconds.\n",
      "\n",
      "day_month=Pandas(Index=50, day=3, month=4), target=2011-04-03 00:00:00\n",
      "Elapsed time: 107.864308 seconds.\n",
      "\n",
      "running mean skill = 0.313997941237\n",
      "Elapsed time: 0.583091 seconds.\n",
      "\n",
      "day_month=Pandas(Index=51, day=17, month=4), target=2011-04-17 00:00:00\n",
      "Elapsed time: 108.216960 seconds.\n",
      "\n",
      "running mean skill = 0.311124936145\n",
      "Elapsed time: 0.624401 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_cores = 8\n",
    "# For the target (day, month) combination, fit leave-one-year regression model \n",
    "# on training set subsetted to relevant margin and generate predictions for each \n",
    "# held-out year\n",
    "prediction_func = rolling_linear_regression_wrapper\n",
    "all_preds = pd.DataFrame()\n",
    "\n",
    "generic_year = 2011\n",
    "for day_month in target_day_months.itertuples():\n",
    "    # Get target date on generic as a datetime object\n",
    "    target_date_obj = datetime.strptime('{}{:02d}{:02d}'.format(\n",
    "        generic_year, day_month.month, day_month.day), \"%Y%m%d\")\n",
    "    print 'day_month={}, target={}'.format(day_month, target_date_obj)\n",
    "    # Get number of days between start date of observation period used for prediction\n",
    "    # (2 weeks ahead) and start date of target period (2 or 4 weeks ahead) + 1 day do \n",
    "    # to practical constraints of submission\n",
    "    start_delta = get_start_delta(target_horizon) # 29 or 43\n",
    "    # Create template for held-out years: each held-out year will run from \n",
    "    # last_train_date + 1 on that year (inclusive) through last_train_date\n",
    "    # of the next year (inclusive)\n",
    "    last_train_date = target_date_obj - timedelta(start_delta)\n",
    "    if margin_in_days is not None:\n",
    "        tic()\n",
    "        sub_data = month_day_subset(data, target_date_obj, margin_in_days)\n",
    "        toc()\n",
    "    else:\n",
    "        sub_data = data\n",
    "    tic()\n",
    "    preds = apply_parallel(sub_data.groupby(group_by_cols),\n",
    "                           prediction_func, num_cores,\n",
    "                           x_cols=x_cols, \n",
    "                           base_col=base_col, \n",
    "                           clim_col=clim_col, \n",
    "                           anom_col=anom_col, \n",
    "                           last_train_date=last_train_date)\n",
    "    preds = preds.reset_index() \n",
    "    # Only keep the predictions from the target day and month\n",
    "    preds = preds[(preds.start_date.dt.day == target_date_obj.day) & \n",
    "                  (preds.start_date.dt.month == target_date_obj.month)]\n",
    "    # Concatenate predictions\n",
    "    all_preds = pd.concat([all_preds, preds])\n",
    "    toc()\n",
    "    #---------------\n",
    "    # Evaluate only on target dates                                                        \n",
    "    #---------------\n",
    "    tic()\n",
    "    skills = get_col_skill(\n",
    "        all_preds[all_preds.start_date.isin(target_dates)], \n",
    "        \"truth\", \"forecast\", time_average = False)\n",
    "    print \"running mean skill = {}\".format(skills.mean())\n",
    "    toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    day  month\n",
       "0     2      5\n",
       "1    16      5\n",
       "2    30      5\n",
       "3    13      6\n",
       "4    27      6\n",
       "5    11      7\n",
       "6    25      7\n",
       "7     8      8\n",
       "8    22      8\n",
       "9     5      9\n",
       "10   19      9\n",
       "11    3     10\n",
       "12   17     10\n",
       "13   31     10\n",
       "14   14     11\n",
       "15   28     11\n",
       "16   12     12\n",
       "17   26     12\n",
       "18    9      1\n",
       "19   23      1\n",
       "20    6      2\n",
       "21   20      2\n",
       "22    5      3\n",
       "23   19      3\n",
       "24    2      4\n",
       "25   16      4\n",
       "48    6      3\n",
       "49   20      3\n",
       "50    3      4\n",
       "51   17      4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_day_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall mean skill = 0.311124936145\n",
      "2017-2018 mean skill = 0.280716584179\n",
      "Elapsed time: 0.614542 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#---------------\n",
    "# Evaluate on all target dates                                                        \n",
    "#---------------\n",
    "tic()\n",
    "skills = get_col_skill(\n",
    "    all_preds[all_preds.start_date.isin(target_dates)], \n",
    "    \"truth\", \"forecast\", time_average = False)\n",
    "print \"overall mean skill = {}\".format(skills.mean())\n",
    "#---------------\n",
    "# Evaluate on contest year                                                      \n",
    "#---------------\n",
    "skills = get_col_skill(\n",
    "    all_preds[all_preds.start_date.isin(target_dates) & (all_preds.start_date >= \n",
    "              get_target_date(\"20170418\", target_horizon))], \n",
    "    \"truth\", \"forecast\", time_average = False)\n",
    "print \"2017-2018 mean skill = {}\".format(skills.mean())\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to results/regression/2011-2018/contest_tmp2m_34w/3398913618608284965/preds-contest_tmp2m-34w-days60-early337.h5\n",
      "Elapsed time: 0.192340 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Save target date predictions to file\n",
    "#\n",
    "\n",
    "# Ensure hash randomization turned off for reproducibility\n",
    "PYTHONHASHSEED=0\n",
    "# Define a compact string identifier for experiment parameters\n",
    "param_str = str(abs(hash((base_col, frozenset(x_cols), margin_in_days, frozenset(group_by_cols),\n",
    "                         anom_scale_col, pred_anom_scale_col))))\n",
    "# Create directory for storing results\n",
    "outdir = os.path.join('results',experiment,'2011-2018',gt_id+'_'+target_horizon,param_str)\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "# Write predictions to file; record the dependency on the type of knn features integrated\n",
    "# into the feature set in the file name\n",
    "preds_file = os.path.join(\n",
    "    outdir,'preds-{}-{}-days{}-early{}.h5'.format(gt_id,target_horizon,past_days,days_early))\n",
    "print \"Saving predictions to \"+preds_file; tic()\n",
    "all_preds[all_preds.start_date.isin(target_dates)].to_hdf(preds_file, key=\"data\", mode=\"w\"); toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
